{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5092894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Reading data\n",
    "data = pd.read_csv(\"merged_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea467887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     86275\n",
      "           1       0.00      0.00      0.00        99\n",
      "           2       0.00      0.00      0.00        93\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        96\n",
      "           5       0.00      0.00      0.00        56\n",
      "           6       0.00      0.00      0.00        36\n",
      "           7       0.00      0.00      0.00        42\n",
      "           8       0.00      0.00      0.00        39\n",
      "           9       0.00      0.00      0.00        37\n",
      "          10       0.00      0.00      0.00        27\n",
      "          11       0.00      0.00      0.00        22\n",
      "          12       0.00      0.00      0.00        20\n",
      "          13       0.00      0.00      0.00        13\n",
      "          14       0.00      0.00      0.00        13\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00        11\n",
      "          17       0.00      0.00      0.00        13\n",
      "          18       0.00      0.00      0.00         9\n",
      "          19       0.00      0.00      0.00         6\n",
      "          20       0.00      0.00      0.00         6\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.00      0.00        82\n",
      "\n",
      "    accuracy                           0.99     87101\n",
      "   macro avg       0.04      0.04      0.04     87101\n",
      "weighted avg       0.98      0.99      0.99     87101\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# *********************************************************************************************************************\n",
    "# Predict delay bin including 0 delay\n",
    "# *********************************************************************************************************************\n",
    "\n",
    "# Loading Inputs\n",
    "input_features = [\"wind_dir\", \"wind_speed\", \"ceiling\", \"visibility\", \"temp\", \"dew_pnt\", \"pressure\", \"congestion_score\", \"time_of_day\", \"time_diff\"]\n",
    "X = data[input_features]\n",
    "\n",
    "# Loading Outputs (5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, inf)\n",
    "y = data[\"delay_bin\"]\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test = X[:int(len(data)*0.75)], X[int(len(data)*0.75):]\n",
    "y_train, y_test = y[:int(len(data)*0.75)], y[int(len(data)*0.75):]\n",
    "\n",
    "# Building the model\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,              # fraction of samples per tree\n",
    "    colsample_bytree=0.8,       # fraction of features per tree\n",
    "    num_class=25,\n",
    "    eval_metric='mlogloss',\n",
    "    objective='multi:softmax'\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8399efc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.int64(0): np.float64(0.04039060960293692), np.int64(1): np.float64(26.06503740648379), np.int64(2): np.float64(33.93532467532467), np.int64(3): np.float64(42.83639344262295), np.int64(4): np.float64(46.45368888888889), np.int64(5): np.float64(67.43277419354838), np.int64(6): np.float64(69.21907284768211), np.int64(7): np.float64(91.68491228070175), np.int64(8): np.float64(101.47650485436893), np.int64(9): np.float64(129.03802469135803), np.int64(10): np.float64(132.30481012658228), np.int64(11): np.float64(160.80123076923076), np.int64(12): np.float64(186.6442857142857), np.int64(13): np.float64(204.9427450980392), np.int64(14): np.float64(282.4886486486486), np.int64(15): np.float64(337.16387096774196), np.int64(16): np.float64(261.302), np.int64(17): np.float64(418.0832), np.int64(18): np.float64(497.71809523809526), np.int64(19): np.float64(418.0832), np.int64(20): np.float64(475.0945454545455), np.int64(21): np.float64(435.50333333333333), np.int64(22): np.float64(653.255), np.int64(23): np.float64(696.8053333333334), np.int64(24): np.float64(43.916302521008404)}\n",
      "Accuracy: 0.7328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.74      0.85     86275\n",
      "           1       0.00      0.12      0.00        99\n",
      "           2       0.01      0.17      0.01        93\n",
      "           3       0.00      0.05      0.00        87\n",
      "           4       0.00      0.04      0.00        96\n",
      "           5       0.00      0.00      0.00        56\n",
      "           6       0.00      0.03      0.00        36\n",
      "           7       0.00      0.00      0.00        42\n",
      "           8       0.00      0.05      0.00        39\n",
      "           9       0.00      0.03      0.00        37\n",
      "          10       0.00      0.00      0.00        27\n",
      "          11       0.00      0.00      0.00        22\n",
      "          12       0.00      0.00      0.00        20\n",
      "          13       0.00      0.00      0.00        13\n",
      "          14       0.00      0.00      0.00        13\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00        11\n",
      "          17       0.00      0.00      0.00        13\n",
      "          18       0.00      0.00      0.00         9\n",
      "          19       0.00      0.00      0.00         6\n",
      "          20       0.00      0.00      0.00         6\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.02      0.00        82\n",
      "\n",
      "    accuracy                           0.73     87101\n",
      "   macro avg       0.04      0.05      0.04     87101\n",
      "weighted avg       0.99      0.73      0.84     87101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# *********************************************************************************************************************\n",
    "# Predict delay bin including 0 delay, and using class weights\n",
    "# *********************************************************************************************************************\n",
    "\n",
    "# Loading Inputs\n",
    "input_features = [\"wind_dir\", \"wind_speed\", \"ceiling\", \"visibility\", \"temp\", \"dew_pnt\", \"pressure\", \"congestion_score\", \"time_of_day\", \"time_diff\"]\n",
    "X = data[input_features]\n",
    "\n",
    "# Loading Outputs (5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, inf)\n",
    "y = data[\"delay_bin\"]\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test = X[:int(len(data)*0.75)], X[int(len(data)*0.75):]\n",
    "y_train, y_test = y[:int(len(data)*0.75)], y[int(len(data)*0.75):]\n",
    "\n",
    "# Building Class weights\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes,\n",
    "    y=y_train\n",
    ")\n",
    "weight_dict = dict(zip(classes, class_weights))\n",
    "\n",
    "# Showing weights\n",
    "print(weight_dict)\n",
    "\n",
    "# Building the model\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,              # fraction of samples per tree\n",
    "    colsample_bytree=0.8,       # fraction of features per tree\n",
    "    num_class=25,\n",
    "    eval_metric='mlogloss',\n",
    "    objective='multi:softmax'\n",
    ")\n",
    "\n",
    "# Mapping each training sample to its class weight\n",
    "sample_weights = y_train.map(weight_dict)\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca8d761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.6261\n",
      "Accuracy: 0.4970\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.98      0.70       839\n",
      "           1       0.05      0.04      0.04       100\n",
      "           2       0.14      0.06      0.09        94\n",
      "           3       0.00      0.00      0.00        88\n",
      "           4       0.29      0.02      0.04        97\n",
      "           5       0.00      0.00      0.00        57\n",
      "           6       0.00      0.00      0.00        38\n",
      "           7       0.00      0.00      0.00        42\n",
      "           8       0.50      0.03      0.05        40\n",
      "           9       0.00      0.00      0.00        37\n",
      "          10       0.00      0.00      0.00        28\n",
      "          11       0.00      0.00      0.00        23\n",
      "          12       0.00      0.00      0.00        20\n",
      "          13       0.00      0.00      0.00        14\n",
      "          14       0.00      0.00      0.00        13\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00        11\n",
      "          17       0.00      0.00      0.00        13\n",
      "          18       0.00      0.00      0.00         9\n",
      "          19       0.00      0.00      0.00         6\n",
      "          20       0.00      0.00      0.00         6\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.00      0.00        84\n",
      "\n",
      "    accuracy                           0.50      1678\n",
      "   macro avg       0.06      0.05      0.04      1678\n",
      "weighted avg       0.31      0.50      0.36      1678\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# *********************************************************************************************************************\n",
    "# Predict delay bin including 0 delay, and balancing 0 delay data to delay data size\n",
    "# *********************************************************************************************************************\n",
    "\n",
    "# Extract 0 delay data, and above 0 delay data\n",
    "no_delay = data[data[\"yes_delay\"] == False]\n",
    "yes_delay = data[data[\"yes_delay\"]]\n",
    "\n",
    "# Sampling 0 delay data (THERE IS POTENTIAL DATA LEAKAGE)\n",
    "no_delay_sample = no_delay.sample(n=len(yes_delay))\n",
    "\n",
    "# Building training data sets\n",
    "yes_delay_train = yes_delay[:int(len(yes_delay)*0.75)]\n",
    "no_delay_train = no_delay_sample[:int(len(no_delay_sample)*0.75)]\n",
    "train_data = pd.concat([yes_delay_train, no_delay_train], ignore_index=False) # combining datasets\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True) # Shuffling training data\n",
    "\n",
    "input_features = [\"wind_dir\", \"wind_speed\", \"ceiling\", \"visibility\", \"temp\", \"dew_pnt\", \"pressure\", \"congestion_score\", \"time_of_day\", \"time_diff\"]\n",
    "X_train = train_data[input_features]\n",
    "y_train = train_data[\"delay_bin\"]\n",
    "\n",
    "# Building testing data sets\n",
    "yes_delay_test = yes_delay[int(len(yes_delay)*0.75):]\n",
    "no_delay_test = no_delay_sample[int(len(no_delay_sample)*0.75):]\n",
    "test_data = pd.concat([yes_delay_test, no_delay_test], ignore_index=False) # combining datasets\n",
    "test_data = test_data.sample(frac=1).reset_index(drop=True) # Shuffling training data\n",
    "\n",
    "input_features = [\"wind_dir\", \"wind_speed\", \"ceiling\", \"visibility\", \"temp\", \"dew_pnt\", \"pressure\", \"congestion_score\", \"time_of_day\", \"time_diff\"]\n",
    "X_test = test_data[input_features]\n",
    "y_test = test_data[\"delay_bin\"]\n",
    "\n",
    "# Building the model\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,              # fraction of samples per tree\n",
    "    colsample_bytree=0.8,       # fraction of features per tree\n",
    "    num_class=25,\n",
    "    eval_metric='mlogloss',\n",
    "    objective='multi:softmax'\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Checking Overfitting\n",
    "y_train_pred = model.predict(X_train)\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Training Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea0eeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.int64(0): np.float64(0.08), np.int64(1): np.float64(0.7733333333333333), np.int64(2): np.float64(0.58), np.int64(3): np.float64(0.696), np.int64(4): np.float64(0.9942857142857143), np.int64(5): np.float64(2.32), np.int64(6): np.float64(1.16), np.int64(7): np.float64(1.74), np.int64(8): np.float64(1.2654545454545454), np.int64(9): np.float64(2.32), np.int64(10): np.float64(3.48), np.int64(11): np.float64(2.784), np.int64(12): np.float64(13.92), np.int64(13): np.float64(13.92), np.int64(14): np.float64(3.48), np.int64(15): np.float64(13.92), np.int64(16): np.float64(3.48), np.int64(17): np.float64(6.96), np.int64(18): np.float64(4.64), np.int64(19): np.float64(3.48), np.int64(20): np.float64(6.96), np.int64(21): np.float64(13.92), np.int64(22): np.float64(13.92), np.int64(23): np.float64(4.64), np.int64(24): np.float64(0.7326315789473684)}\n",
      "Training Accuracy: 0.9598\n",
      "Testing Accuracy: 0.3729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.73      0.64        59\n",
      "           1       0.00      0.00      0.00         9\n",
      "           2       0.12      0.12      0.12         8\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00         6\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         4\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       0.00      0.00      0.00         4\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         3\n",
      "          14       0.00      0.00      0.00         3\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         2\n",
      "          21       0.00      0.00      0.00         1\n",
      "          23       0.00      0.00      0.00         0\n",
      "          24       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.37       118\n",
      "   macro avg       0.03      0.04      0.04       118\n",
      "weighted avg       0.29      0.37      0.33       118\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# *********************************************************************************************************************\n",
    "# Predict delay bin including 0 delay, using class weights, and balancing 0 delay data to delay data size\n",
    "# *********************************************************************************************************************\n",
    "\n",
    "# Extract 0 delay data, and above 0 delay data\n",
    "no_delay = data[data[\"yes_delay\"] == False]\n",
    "yes_delay = data[data[\"yes_delay\"]]\n",
    "\n",
    "# Sampling 0 delay data (THERE IS POTENTIAL DATA LEAKAGE)\n",
    "no_delay_sample = no_delay.sample(n=len(yes_delay))\n",
    "\n",
    "# Building training data sets\n",
    "yes_delay_train = yes_delay[:int(len(yes_delay)*0.75)]\n",
    "no_delay_train = no_delay_sample[:int(len(no_delay_sample)*0.75)]\n",
    "train_data = pd.concat([yes_delay_train, no_delay_train], ignore_index=False) # combining datasets\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True) # Shuffling training data\n",
    "\n",
    "input_features = [\"wind_dir\", \"wind_speed\", \"ceiling\", \"visibility\", \"temp\", \"dew_pnt\", \"pressure\", \"congestion_score\", \"time_of_day\", \"time_diff\"]\n",
    "X_train = train_data[input_features]\n",
    "y_train = train_data[\"delay_bin\"]\n",
    "\n",
    "# Building testing data sets\n",
    "yes_delay_test = yes_delay[int(len(yes_delay)*0.75):]\n",
    "no_delay_test = no_delay_sample[int(len(no_delay_sample)*0.75):]\n",
    "test_data = pd.concat([yes_delay_test, no_delay_test], ignore_index=False) # combining datasets\n",
    "test_data = test_data.sample(frac=1).reset_index(drop=True) # Shuffling training data\n",
    "\n",
    "input_features = [\"wind_dir\", \"wind_speed\", \"ceiling\", \"visibility\", \"temp\", \"dew_pnt\", \"pressure\", \"congestion_score\", \"time_of_day\", \"time_diff\"]\n",
    "X_test = test_data[input_features]\n",
    "y_test = test_data[\"delay_bin\"]\n",
    "\n",
    "# Building Class weights\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes,\n",
    "    y=y_train\n",
    ")\n",
    "weight_dict = dict(zip(classes, class_weights))\n",
    "\n",
    "# Showing weights\n",
    "print(weight_dict)\n",
    "\n",
    "# Building the model\n",
    "model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,              # fraction of samples per tree\n",
    "    colsample_bytree=0.8,       # fraction of features per tree\n",
    "    num_class=25,\n",
    "    eval_metric='mlogloss',\n",
    "    objective='multi:softmax'\n",
    ")\n",
    "\n",
    "# Mapping each training sample to its class weight\n",
    "sample_weights = y_train.map(weight_dict)\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# Checking Overfitting\n",
    "y_train_pred = model.predict(X_train)\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Training Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Testing Accuracy: {acc:.4f}\")\n",
    "print(pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "15a6f6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9371\n",
      "Testing Accuracy: 0.6492\n",
      "              precision    recall  f1-score      support\n",
      "False          0.628099  0.731774  0.675985   727.000000\n",
      "True           0.678748  0.566713  0.617691   727.000000\n",
      "accuracy       0.649243  0.649243  0.649243     0.649243\n",
      "macro avg      0.653424  0.649243  0.646838  1454.000000\n",
      "weighted avg   0.653424  0.649243  0.646838  1454.000000\n"
     ]
    }
   ],
   "source": [
    "# *********************************************************************************************************************\n",
    "# Build one model to predict yes/no delay\n",
    "# Which will later be used in combination with the model which predicts delay bin\n",
    "# *********************************************************************************************************************\n",
    "\n",
    "data = data[data[\"time_diff\"]<61]\n",
    "\n",
    "# Extract 0 delay data, and above 0 delay data\n",
    "no_delay = data[data[\"yes_delay\"] == False]\n",
    "yes_delay = data[data[\"yes_delay\"]]\n",
    "\n",
    "# Sampling 0 delay data (THERE IS POTENTIAL DATA LEAKAGE)\n",
    "no_delay_sample = no_delay.sample(n=len(yes_delay))\n",
    "\n",
    "# Building training data sets\n",
    "yes_delay_train = yes_delay[:int(len(yes_delay)*0.75)]\n",
    "no_delay_train = no_delay_sample[:int(len(no_delay_sample)*0.75)]\n",
    "train_data = pd.concat([yes_delay_train, no_delay_train], ignore_index=False) # combining datasets\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True) # Shuffling training data\n",
    "\n",
    "input_features = [\"wind_dir\", \"wind_speed\", \"ceiling\", \"visibility\", \"temp\", \"dew_pnt\", \"pressure\", \"congestion_score\", \"time_of_day\", \"time_diff\"]\n",
    "X_train = train_data[input_features]\n",
    "y_train = train_data[\"yes_delay\"] == True\n",
    "\n",
    "# Building testing data sets\n",
    "yes_delay_test = yes_delay[int(len(yes_delay)*0.75):]\n",
    "no_delay_test = no_delay_sample[int(len(no_delay_sample)*0.75):]\n",
    "test_data = pd.concat([yes_delay_test, no_delay_test], ignore_index=False) # combining datasets\n",
    "test_data = test_data.sample(frac=1).reset_index(drop=True) # Shuffling training data\n",
    "\n",
    "input_features = [\"wind_dir\", \"wind_speed\", \"ceiling\", \"visibility\", \"temp\", \"dew_pnt\", \"pressure\", \"congestion_score\", \"time_of_day\", \"time_diff\"]\n",
    "X_test = test_data[input_features]\n",
    "y_test = test_data[\"yes_delay\"] == True\n",
    "\n",
    "# Building the model\n",
    "model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,              # fraction of samples per tree\n",
    "    colsample_bytree=0.8,       # fraction of features per tree\n",
    "    num_class=2,\n",
    "    eval_metric='mlogloss',\n",
    "    objective='multi:softmax'\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Checking Overfitting\n",
    "y_train_pred = model.predict(X_train)\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Training Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Testing Accuracy: {acc:.4f}\")\n",
    "print(pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f199982f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2248\n",
      "              precision    recall  f1-score      support\n",
      "0              0.268608  0.631980  0.376987   394.000000\n",
      "1              0.196931  0.226471  0.210670   340.000000\n",
      "2              0.180000  0.136364  0.155172   198.000000\n",
      "3              0.107143  0.018868  0.032086   159.000000\n",
      "4              0.052632  0.015625  0.024096   128.000000\n",
      "5              0.047619  0.013514  0.021053    74.000000\n",
      "6              0.000000  0.000000  0.000000    61.000000\n",
      "7              0.000000  0.000000  0.000000    46.000000\n",
      "8              0.000000  0.000000  0.000000    39.000000\n",
      "9              0.000000  0.000000  0.000000    31.000000\n",
      "10             0.000000  0.000000  0.000000    27.000000\n",
      "11             0.163636  0.100000  0.124138   180.000000\n",
      "accuracy       0.224806  0.224806  0.224806     0.224806\n",
      "macro avg      0.084714  0.095235  0.078684  1677.000000\n",
      "weighted avg   0.158127  0.224806  0.168738  1677.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# *********************************************************************************************************************\n",
    "# Build another model to predict time delay bin if yes delay\n",
    "# *********************************************************************************************************************\n",
    "\n",
    "# Extract above 0 delay data\n",
    "yes_delay = data[data[\"yes_delay\"]]\n",
    "\n",
    "# Loading Inputs\n",
    "input_features = [\"wind_dir\", \"wind_speed\", \"ceiling\", \"visibility\", \"temp\", \"dew_pnt\", \"pressure\", \"congestion_score\", \"time_of_day\", \"time_diff\"]\n",
    "X = yes_delay[input_features]\n",
    "\n",
    "# Loading Outputs\n",
    "y = (yes_delay[\"delay_bin\"]-1)//2\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test = X[:int(len(yes_delay)*0.5)], X[int(len(yes_delay)*0.5):]\n",
    "y_train, y_test = y[:int(len(yes_delay)*0.5)], y[int(len(yes_delay)*0.5):]\n",
    "\n",
    "# Building the model\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,              # fraction of samples per tree\n",
    "    colsample_bytree=0.8,       # fraction of features per tree\n",
    "    eval_metric='mlogloss',\n",
    "    objective='multi:softmax'\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
