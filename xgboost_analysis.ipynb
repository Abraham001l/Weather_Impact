{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5092894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Reading data\n",
    "data = pd.read_csv(\"merged_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea467887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     86275\n",
      "           1       0.00      0.00      0.00        99\n",
      "           2       0.00      0.00      0.00        93\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        96\n",
      "           5       0.00      0.00      0.00        56\n",
      "           6       0.00      0.00      0.00        36\n",
      "           7       0.00      0.00      0.00        42\n",
      "           8       0.00      0.00      0.00        39\n",
      "           9       0.00      0.00      0.00        37\n",
      "          10       0.00      0.00      0.00        27\n",
      "          11       0.00      0.00      0.00        22\n",
      "          12       0.00      0.00      0.00        20\n",
      "          13       0.00      0.00      0.00        13\n",
      "          14       0.00      0.00      0.00        13\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00        11\n",
      "          17       0.00      0.00      0.00        13\n",
      "          18       0.00      0.00      0.00         9\n",
      "          19       0.00      0.00      0.00         6\n",
      "          20       0.00      0.00      0.00         6\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.00      0.00        82\n",
      "\n",
      "    accuracy                           0.99     87101\n",
      "   macro avg       0.04      0.04      0.04     87101\n",
      "weighted avg       0.98      0.99      0.99     87101\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# *********************************************************************************************************************\n",
    "# Predict delay bin including 0 delay\n",
    "# *********************************************************************************************************************\n",
    "\n",
    "# Loading Inputs\n",
    "input_features = [\"wind_dir\", \"wind_speed\", \"ceiling\", \"visibility\", \"temp\", \"dew_pnt\", \"pressure\", \"congestion_score\", \"time_of_day\", \"time_diff\"]\n",
    "X = data[input_features]\n",
    "\n",
    "# Loading Outputs (5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, inf)\n",
    "y = data[\"delay_bin\"]\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test = X[:int(len(data)*0.75)], X[int(len(data)*0.75):]\n",
    "y_train, y_test = y[:int(len(data)*0.75)], y[int(len(data)*0.75):]\n",
    "\n",
    "# Building the model\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,              # fraction of samples per tree\n",
    "    colsample_bytree=0.8,       # fraction of features per tree\n",
    "    num_class=25,\n",
    "    eval_metric='mlogloss',\n",
    "    objective='multi:softmax'\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8399efc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.int64(0): np.float64(0.04039060960293692), np.int64(1): np.float64(26.06503740648379), np.int64(2): np.float64(33.93532467532467), np.int64(3): np.float64(42.83639344262295), np.int64(4): np.float64(46.45368888888889), np.int64(5): np.float64(67.43277419354838), np.int64(6): np.float64(69.21907284768211), np.int64(7): np.float64(91.68491228070175), np.int64(8): np.float64(101.47650485436893), np.int64(9): np.float64(129.03802469135803), np.int64(10): np.float64(132.30481012658228), np.int64(11): np.float64(160.80123076923076), np.int64(12): np.float64(186.6442857142857), np.int64(13): np.float64(204.9427450980392), np.int64(14): np.float64(282.4886486486486), np.int64(15): np.float64(337.16387096774196), np.int64(16): np.float64(261.302), np.int64(17): np.float64(418.0832), np.int64(18): np.float64(497.71809523809526), np.int64(19): np.float64(418.0832), np.int64(20): np.float64(475.0945454545455), np.int64(21): np.float64(435.50333333333333), np.int64(22): np.float64(653.255), np.int64(23): np.float64(696.8053333333334), np.int64(24): np.float64(43.916302521008404)}\n",
      "Accuracy: 0.7328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.74      0.85     86275\n",
      "           1       0.00      0.12      0.00        99\n",
      "           2       0.01      0.17      0.01        93\n",
      "           3       0.00      0.05      0.00        87\n",
      "           4       0.00      0.04      0.00        96\n",
      "           5       0.00      0.00      0.00        56\n",
      "           6       0.00      0.03      0.00        36\n",
      "           7       0.00      0.00      0.00        42\n",
      "           8       0.00      0.05      0.00        39\n",
      "           9       0.00      0.03      0.00        37\n",
      "          10       0.00      0.00      0.00        27\n",
      "          11       0.00      0.00      0.00        22\n",
      "          12       0.00      0.00      0.00        20\n",
      "          13       0.00      0.00      0.00        13\n",
      "          14       0.00      0.00      0.00        13\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00        11\n",
      "          17       0.00      0.00      0.00        13\n",
      "          18       0.00      0.00      0.00         9\n",
      "          19       0.00      0.00      0.00         6\n",
      "          20       0.00      0.00      0.00         6\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.02      0.00        82\n",
      "\n",
      "    accuracy                           0.73     87101\n",
      "   macro avg       0.04      0.05      0.04     87101\n",
      "weighted avg       0.99      0.73      0.84     87101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# *********************************************************************************************************************\n",
    "# Predict delay bin including 0 delay, and using class weights\n",
    "# *********************************************************************************************************************\n",
    "\n",
    "# Loading Inputs\n",
    "input_features = [\"wind_dir\", \"wind_speed\", \"ceiling\", \"visibility\", \"temp\", \"dew_pnt\", \"pressure\", \"congestion_score\", \"time_of_day\", \"time_diff\"]\n",
    "X = data[input_features]\n",
    "\n",
    "# Loading Outputs (5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, inf)\n",
    "y = data[\"delay_bin\"]\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test = X[:int(len(data)*0.75)], X[int(len(data)*0.75):]\n",
    "y_train, y_test = y[:int(len(data)*0.75)], y[int(len(data)*0.75):]\n",
    "\n",
    "# Building Class weights\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes,\n",
    "    y=y_train\n",
    ")\n",
    "weight_dict = dict(zip(classes, class_weights))\n",
    "\n",
    "# Showing weights\n",
    "print(weight_dict)\n",
    "\n",
    "# Building the model\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,              # fraction of samples per tree\n",
    "    colsample_bytree=0.8,       # fraction of features per tree\n",
    "    num_class=25,\n",
    "    eval_metric='mlogloss',\n",
    "    objective='multi:softmax'\n",
    ")\n",
    "\n",
    "# Mapping each training sample to its class weight\n",
    "sample_weights = y_train.map(weight_dict)\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ca8d761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.6275\n",
      "Accuracy: 0.4934\n",
      "              precision    recall  f1-score      support\n",
      "0              0.536634  0.969011  0.690739   839.000000\n",
      "1              0.073529  0.050000  0.059524   100.000000\n",
      "2              0.080000  0.042553  0.055556    94.000000\n",
      "3              0.222222  0.022727  0.041237    88.000000\n",
      "4              0.142857  0.020619  0.036036    97.000000\n",
      "5              0.000000  0.000000  0.000000    57.000000\n",
      "6              0.000000  0.000000  0.000000    38.000000\n",
      "7              0.000000  0.000000  0.000000    42.000000\n",
      "8              0.000000  0.000000  0.000000    40.000000\n",
      "9              0.000000  0.000000  0.000000    37.000000\n",
      "10             0.000000  0.000000  0.000000    28.000000\n",
      "11             0.000000  0.000000  0.000000    23.000000\n",
      "12             0.000000  0.000000  0.000000    20.000000\n",
      "13             0.000000  0.000000  0.000000    14.000000\n",
      "14             0.000000  0.000000  0.000000    13.000000\n",
      "15             0.000000  0.000000  0.000000     8.000000\n",
      "16             0.000000  0.000000  0.000000    11.000000\n",
      "17             0.000000  0.000000  0.000000    13.000000\n",
      "18             0.000000  0.000000  0.000000     9.000000\n",
      "19             0.000000  0.000000  0.000000     6.000000\n",
      "20             0.000000  0.000000  0.000000     6.000000\n",
      "21             0.000000  0.000000  0.000000     3.000000\n",
      "22             0.000000  0.000000  0.000000     5.000000\n",
      "23             0.000000  0.000000  0.000000     3.000000\n",
      "24             0.117647  0.023810  0.039604    84.000000\n",
      "accuracy       0.493445  0.493445  0.493445     0.493445\n",
      "macro avg      0.046916  0.045149  0.036908  1678.000000\n",
      "weighted avg   0.302982  0.493445  0.358257  1678.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# *********************************************************************************************************************\n",
    "# Predict delay bin including 0 delay, and balancing 0 delay data to delay data size\n",
    "# *********************************************************************************************************************\n",
    "\n",
    "# Extract 0 delay data, and above 0 delay data\n",
    "no_delay = data[data[\"yes_delay\"] == False]\n",
    "yes_delay = data[data[\"yes_delay\"]]\n",
    "\n",
    "# Sampling 0 delay data (THERE IS POTENTIAL DATA LEAKAGE)\n",
    "no_delay_sample = no_delay.sample(n=len(yes_delay))\n",
    "\n",
    "# Building training data sets\n",
    "yes_delay_train = yes_delay[:int(len(yes_delay)*0.75)]\n",
    "no_delay_train = no_delay_sample[:int(len(no_delay_sample)*0.75)]\n",
    "train_data = pd.concat([yes_delay_train, no_delay_train], ignore_index=False) # combining datasets\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True) # Shuffling training data\n",
    "\n",
    "input_features = [\"wind_dir\", \"wind_speed\", \"ceiling\", \"visibility\", \"temp\", \"dew_pnt\", \"pressure\", \"congestion_score\", \"time_of_day\", \"time_diff\"]\n",
    "X_train = train_data[input_features]\n",
    "y_train = train_data[\"delay_bin\"]\n",
    "\n",
    "# Building testing data sets\n",
    "yes_delay_test = yes_delay[int(len(yes_delay)*0.75):]\n",
    "no_delay_test = no_delay_sample[int(len(no_delay_sample)*0.75):]\n",
    "test_data = pd.concat([yes_delay_test, no_delay_test], ignore_index=False) # combining datasets\n",
    "test_data = test_data.sample(frac=1).reset_index(drop=True) # Shuffling training data\n",
    "\n",
    "input_features = [\"wind_dir\", \"wind_speed\", \"ceiling\", \"visibility\", \"temp\", \"dew_pnt\", \"pressure\", \"congestion_score\", \"time_of_day\", \"time_diff\"]\n",
    "X_test = test_data[input_features]\n",
    "y_test = test_data[\"delay_bin\"]\n",
    "\n",
    "# Building the model\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,              # fraction of samples per tree\n",
    "    colsample_bytree=0.8,       # fraction of features per tree\n",
    "    num_class=25,\n",
    "    eval_metric='mlogloss',\n",
    "    objective='multi:softmax'\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Checking Overfitting\n",
    "y_train_pred = model.predict(X_train)\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Training Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea0eeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.int64(0): np.float64(0.08), np.int64(1): np.float64(0.5028), np.int64(2): np.float64(0.655114006514658), np.int64(3): np.float64(0.8276543209876543), np.int64(4): np.float64(0.8978571428571429), np.int64(5): np.float64(1.305974025974026), np.int64(6): np.float64(1.349798657718121), np.int64(7): np.float64(1.7642105263157895), np.int64(8): np.float64(1.9717647058823529), np.int64(9): np.float64(2.482962962962963), np.int64(10): np.float64(2.5784615384615384), np.int64(11): np.float64(3.1425), np.int64(12): np.float64(3.5914285714285716), np.int64(13): np.float64(4.0224), np.int64(14): np.float64(5.435675675675676), np.int64(15): np.float64(6.487741935483871), np.int64(16): np.float64(5.028), np.int64(17): np.float64(8.0448), np.int64(18): np.float64(9.577142857142857), np.int64(19): np.float64(8.0448), np.int64(20): np.float64(9.141818181818183), np.int64(21): np.float64(8.38), np.int64(22): np.float64(12.57), np.int64(23): np.float64(13.408), np.int64(24): np.float64(0.8522033898305085)}\n",
      "Training Accuracy: 0.8423\n",
      "Testing Accuracy: 0.3290\n",
      "              precision    recall  f1-score      support\n",
      "0              0.615960  0.588796  0.602072   839.000000\n",
      "1              0.060000  0.120000  0.080000   100.000000\n",
      "2              0.118519  0.170213  0.139738    94.000000\n",
      "3              0.128205  0.113636  0.120482    88.000000\n",
      "4              0.053763  0.051546  0.052632    97.000000\n",
      "5              0.057971  0.070175  0.063492    57.000000\n",
      "6              0.021739  0.026316  0.023810    38.000000\n",
      "7              0.032258  0.023810  0.027397    42.000000\n",
      "8              0.000000  0.000000  0.000000    40.000000\n",
      "9              0.111111  0.054054  0.072727    37.000000\n",
      "10             0.031250  0.035714  0.033333    28.000000\n",
      "11             0.000000  0.000000  0.000000    23.000000\n",
      "12             0.000000  0.000000  0.000000    20.000000\n",
      "13             0.000000  0.000000  0.000000    14.000000\n",
      "14             0.000000  0.000000  0.000000    13.000000\n",
      "15             0.000000  0.000000  0.000000     8.000000\n",
      "16             0.000000  0.000000  0.000000    11.000000\n",
      "17             0.000000  0.000000  0.000000    13.000000\n",
      "18             0.000000  0.000000  0.000000     9.000000\n",
      "19             0.000000  0.000000  0.000000     6.000000\n",
      "20             0.000000  0.000000  0.000000     6.000000\n",
      "21             0.000000  0.000000  0.000000     3.000000\n",
      "22             0.000000  0.000000  0.000000     5.000000\n",
      "23             0.000000  0.000000  0.000000     3.000000\n",
      "24             0.066667  0.071429  0.068966    84.000000\n",
      "accuracy       0.328963  0.328963  0.328963     0.328963\n",
      "macro avg      0.051898  0.053028  0.051386  1678.000000\n",
      "weighted avg   0.337604  0.328963  0.331986  1678.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# *********************************************************************************************************************\n",
    "# Predict delay bin including 0 delay, using class weights, and balancing 0 delay data to delay data size\n",
    "# *********************************************************************************************************************\n",
    "\n",
    "# Extract 0 delay data, and above 0 delay data\n",
    "no_delay = data[data[\"yes_delay\"] == False]\n",
    "yes_delay = data[data[\"yes_delay\"]]\n",
    "\n",
    "# Sampling 0 delay data (THERE IS POTENTIAL DATA LEAKAGE)\n",
    "no_delay_sample = no_delay.sample(n=len(yes_delay))\n",
    "\n",
    "# Building training data sets\n",
    "yes_delay_train = yes_delay[:int(len(yes_delay)*0.75)]\n",
    "no_delay_train = no_delay_sample[:int(len(no_delay_sample)*0.75)]\n",
    "train_data = pd.concat([yes_delay_train, no_delay_train], ignore_index=False) # combining datasets\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True) # Shuffling training data\n",
    "\n",
    "input_features = [\"wind_dir\", \"wind_speed\", \"ceiling\", \"visibility\", \"temp\", \"dew_pnt\", \"pressure\", \"congestion_score\", \"time_of_day\", \"time_diff\"]\n",
    "X_train = train_data[input_features]\n",
    "y_train = train_data[\"delay_bin\"]\n",
    "\n",
    "# Building testing data sets\n",
    "yes_delay_test = yes_delay[int(len(yes_delay)*0.75):]\n",
    "no_delay_test = no_delay_sample[int(len(no_delay_sample)*0.75):]\n",
    "test_data = pd.concat([yes_delay_test, no_delay_test], ignore_index=False) # combining datasets\n",
    "test_data = test_data.sample(frac=1).reset_index(drop=True) # Shuffling training data\n",
    "\n",
    "input_features = [\"wind_dir\", \"wind_speed\", \"ceiling\", \"visibility\", \"temp\", \"dew_pnt\", \"pressure\", \"congestion_score\", \"time_of_day\", \"time_diff\"]\n",
    "X_test = test_data[input_features]\n",
    "y_test = test_data[\"delay_bin\"]\n",
    "\n",
    "# Building Class weights\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes,\n",
    "    y=y_train\n",
    ")\n",
    "weight_dict = dict(zip(classes, class_weights))\n",
    "\n",
    "# Showing weights\n",
    "print(weight_dict)\n",
    "\n",
    "# Building the model\n",
    "model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,              # fraction of samples per tree\n",
    "    colsample_bytree=0.8,       # fraction of features per tree\n",
    "    num_class=25,\n",
    "    eval_metric='mlogloss',\n",
    "    objective='multi:softmax'\n",
    ")\n",
    "\n",
    "# Mapping each training sample to its class weight\n",
    "sample_weights = y_train.map(weight_dict)\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# Checking Overfitting\n",
    "y_train_pred = model.predict(X_train)\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Training Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Testing Accuracy: {acc:.4f}\")\n",
    "print(pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a6f6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7285\n",
      "Accuracy: 0.4911\n",
      "              precision    recall  f1-score      support\n",
      "0              0.546875  0.959476  0.696668   839.000000\n",
      "1              0.000000  0.000000  0.000000   100.000000\n",
      "2              0.101695  0.063830  0.078431    94.000000\n",
      "3              0.090909  0.022727  0.036364    88.000000\n",
      "4              0.000000  0.000000  0.000000    97.000000\n",
      "5              0.000000  0.000000  0.000000    57.000000\n",
      "6              0.055556  0.026316  0.035714    38.000000\n",
      "7              0.000000  0.000000  0.000000    42.000000\n",
      "8              0.000000  0.000000  0.000000    40.000000\n",
      "9              0.086957  0.054054  0.066667    37.000000\n",
      "10             0.000000  0.000000  0.000000    28.000000\n",
      "11             0.000000  0.000000  0.000000    23.000000\n",
      "12             0.000000  0.000000  0.000000    20.000000\n",
      "13             0.000000  0.000000  0.000000    14.000000\n",
      "14             0.000000  0.000000  0.000000    13.000000\n",
      "15             0.000000  0.000000  0.000000     8.000000\n",
      "16             0.000000  0.000000  0.000000    11.000000\n",
      "17             0.000000  0.000000  0.000000    13.000000\n",
      "18             0.000000  0.000000  0.000000     9.000000\n",
      "19             0.000000  0.000000  0.000000     6.000000\n",
      "20             0.000000  0.000000  0.000000     6.000000\n",
      "21             0.000000  0.000000  0.000000     3.000000\n",
      "22             0.000000  0.000000  0.000000     5.000000\n",
      "23             0.000000  0.000000  0.000000     3.000000\n",
      "24             0.347826  0.095238  0.149533    84.000000\n",
      "accuracy       0.491061  0.491061  0.491061     0.491061\n",
      "macro avg      0.049193  0.048866  0.042535  1678.000000\n",
      "weighted avg   0.304489  0.491061  0.364399  1678.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# *********************************************************************************************************************\n",
    "# Build one model to predict yes/no delay\n",
    "# Build another model to predict time delay bin if yes delay\n",
    "# *********************************************************************************************************************\n",
    "\n",
    "# REBUILDING MODEL AND DATASETS\n",
    "\n",
    "# Extract 0 delay data, and above 0 delay data\n",
    "no_delay = data[data[\"yes_delay\"] == False]\n",
    "yes_delay = data[data[\"yes_delay\"]]\n",
    "\n",
    "# Sampling 0 delay data (THERE IS POTENTIAL DATA LEAKAGE)\n",
    "no_delay_sample = no_delay.sample(n=len(yes_delay))\n",
    "\n",
    "# Building training data sets\n",
    "yes_delay_train = yes_delay[:int(len(yes_delay)*0.75)]\n",
    "no_delay_train = no_delay_sample[:int(len(no_delay_sample)*0.75)]\n",
    "train_data = pd.concat([yes_delay_train, no_delay_train], ignore_index=False) # combining datasets\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True) # Shuffling training data\n",
    "\n",
    "input_features = [\"wind_dir\", \"wind_speed\", \"ceiling\", \"visibility\", \"temp\", \"dew_pnt\", \"pressure\", \"congestion_score\"]\n",
    "X_train = train_data[input_features]\n",
    "y_train = train_data[\"delay_bin\"]\n",
    "\n",
    "# Building testing data sets\n",
    "yes_delay_test = yes_delay[int(len(yes_delay)*0.75):]\n",
    "no_delay_test = no_delay_sample[int(len(no_delay_sample)*0.75):]\n",
    "test_data = pd.concat([yes_delay_test, no_delay_test], ignore_index=False) # combining datasets\n",
    "test_data = test_data.sample(frac=1).reset_index(drop=True) # Shuffling training data\n",
    "\n",
    "input_features = [\"wind_dir\", \"wind_speed\", \"ceiling\", \"visibility\", \"temp\", \"dew_pnt\", \"pressure\", \"congestion_score\"]\n",
    "X_test = test_data[input_features]\n",
    "y_test = test_data[\"delay_bin\"]\n",
    "\n",
    "# Building the model\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,              # fraction of samples per tree\n",
    "    colsample_bytree=0.8,       # fraction of features per tree\n",
    "    num_class=25,\n",
    "    eval_metric='mlogloss',\n",
    "    objective='multi:softmax'\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Checking Overfitting\n",
    "y_train_pred = model.predict(X_train)\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Training Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
