{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5092894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Reading data\n",
    "data = pd.read_csv(\"merged_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea467887",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:31:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     86275\n",
      "           1       0.00      0.00      0.00        99\n",
      "           2       0.00      0.00      0.00        93\n",
      "           3       0.00      0.00      0.00        87\n",
      "           4       0.00      0.00      0.00        96\n",
      "           5       0.00      0.00      0.00        56\n",
      "           6       0.00      0.00      0.00        36\n",
      "           7       0.00      0.00      0.00        42\n",
      "           8       0.00      0.00      0.00        39\n",
      "           9       0.00      0.00      0.00        37\n",
      "          10       0.00      0.00      0.00        27\n",
      "          11       0.00      0.00      0.00        22\n",
      "          12       0.00      0.00      0.00        20\n",
      "          13       0.00      0.00      0.00        13\n",
      "          14       0.00      0.00      0.00        13\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00        11\n",
      "          17       0.00      0.00      0.00        13\n",
      "          18       0.00      0.00      0.00         9\n",
      "          19       0.00      0.00      0.00         6\n",
      "          20       0.00      0.00      0.00         6\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.00      0.00        82\n",
      "\n",
      "    accuracy                           0.99     87101\n",
      "   macro avg       0.04      0.04      0.04     87101\n",
      "weighted avg       0.98      0.99      0.99     87101\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Predict delay bin including 0 delay\n",
    "\n",
    "# Loading Inputs\n",
    "input_features = [\"wind_dir\", \"wind_speed\", \"ceiling\", \"visibility\", \"temp\", \"dew_pnt\", \"pressure\", \"congestion_score\"]\n",
    "X = data[input_features]\n",
    "\n",
    "# Loading Outputs (5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, inf)\n",
    "y = data[\"delay_bin\"]\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test = X[:int(len(data)*0.75)], X[int(len(data)*0.75):]\n",
    "y_train, y_test = y[:int(len(data)*0.75)], y[int(len(data)*0.75):]\n",
    "\n",
    "# Building the model\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,              # fraction of samples per tree\n",
    "    colsample_bytree=0.8,       # fraction of features per tree\n",
    "    num_class=25,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    objective='multi:softmax'\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8399efc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.int64(0): np.float64(0.04039060960293692), np.int64(1): np.float64(26.06503740648379), np.int64(2): np.float64(33.93532467532467), np.int64(3): np.float64(42.83639344262295), np.int64(4): np.float64(46.45368888888889), np.int64(5): np.float64(67.43277419354838), np.int64(6): np.float64(69.21907284768211), np.int64(7): np.float64(91.68491228070175), np.int64(8): np.float64(101.47650485436893), np.int64(9): np.float64(129.03802469135803), np.int64(10): np.float64(132.30481012658228), np.int64(11): np.float64(160.80123076923076), np.int64(12): np.float64(186.6442857142857), np.int64(13): np.float64(204.9427450980392), np.int64(14): np.float64(282.4886486486486), np.int64(15): np.float64(337.16387096774196), np.int64(16): np.float64(261.302), np.int64(17): np.float64(418.0832), np.int64(18): np.float64(497.71809523809526), np.int64(19): np.float64(418.0832), np.int64(20): np.float64(475.0945454545455), np.int64(21): np.float64(435.50333333333333), np.int64(22): np.float64(653.255), np.int64(23): np.float64(696.8053333333334), np.int64(24): np.float64(43.916302521008404)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abrah\\Desktop\\Projects\\wi_environment\\.venv\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [14:33:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.67      0.80     86275\n",
      "           1       0.00      0.06      0.00        99\n",
      "           2       0.00      0.11      0.01        93\n",
      "           3       0.00      0.10      0.01        87\n",
      "           4       0.00      0.05      0.00        96\n",
      "           5       0.00      0.00      0.00        56\n",
      "           6       0.00      0.03      0.00        36\n",
      "           7       0.00      0.00      0.00        42\n",
      "           8       0.00      0.00      0.00        39\n",
      "           9       0.00      0.05      0.01        37\n",
      "          10       0.00      0.00      0.00        27\n",
      "          11       0.00      0.00      0.00        22\n",
      "          12       0.00      0.00      0.00        20\n",
      "          13       0.00      0.00      0.00        13\n",
      "          14       0.00      0.08      0.01        13\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00        11\n",
      "          17       0.00      0.00      0.00        13\n",
      "          18       0.00      0.00      0.00         9\n",
      "          19       0.00      0.00      0.00         6\n",
      "          20       0.00      0.00      0.00         6\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       0.00      0.00      0.00         3\n",
      "          24       0.00      0.12      0.01        82\n",
      "\n",
      "    accuracy                           0.67     87101\n",
      "   macro avg       0.04      0.05      0.03     87101\n",
      "weighted avg       0.99      0.67      0.79     87101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict delay bin including 0 delay, and using class weights\n",
    "\n",
    "# Loading Inputs\n",
    "input_features = [\"wind_dir\", \"wind_speed\", \"ceiling\", \"visibility\", \"temp\", \"dew_pnt\", \"pressure\", \"congestion_score\"]\n",
    "X = data[input_features]\n",
    "\n",
    "# Loading Outputs (5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, inf)\n",
    "y = data[\"delay_bin\"]\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test = X[:int(len(data)*0.75)], X[int(len(data)*0.75):]\n",
    "y_train, y_test = y[:int(len(data)*0.75)], y[int(len(data)*0.75):]\n",
    "\n",
    "# Building Class weights\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes,\n",
    "    y=y_train\n",
    ")\n",
    "weight_dict = dict(zip(classes, class_weights))\n",
    "\n",
    "# Showing weights\n",
    "print(weight_dict)\n",
    "\n",
    "# Building the model\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,              # fraction of samples per tree\n",
    "    colsample_bytree=0.8,       # fraction of features per tree\n",
    "    num_class=25,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    objective='multi:softmax'\n",
    ")\n",
    "\n",
    "# Mapping each training sample to its class weight\n",
    "sample_weights = y_train.map(weight_dict)\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca8d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict delay bin including 0 delay, and balancing 0 delay data to delay data size\n",
    "\n",
    "# Extract 0 delay data, and above 0 delay data\n",
    "no_delay = data[not data[\"yes_delay\"]]\n",
    "yes_delay = data[data[\"yes_delay\"]]\n",
    "\n",
    "# Sampling 0 delay data (THERE IS POTENTIAL DATA LEAKAGE)\n",
    "no_delay_sample = no_delay.sample(n=len(yes_delay))\n",
    "\n",
    "# Building training data sets\n",
    "yes_delay_train = yes_delay[:int(len(yes_delay)*0.75)]\n",
    "no_delay_train = no_delay_sample[:int(len(no_delay_sample)*0.75)]\n",
    "train_data = pd.concat([yes_delay_train, no_delay_train], ignor_index=False) # combining datasets\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True) # Shuffling training data\n",
    "\n",
    "\n",
    "# Loading Inputs\n",
    "input_features = [\"wind_dir\", \"wind_speed\", \"ceiling\", \"visibility\", \"temp\", \"dew_pnt\", \"pressure\", \"congestion_score\"]\n",
    "X = data[input_features]\n",
    "\n",
    "# Loading Outputs (5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, inf)\n",
    "y = data[\"delay_bin\"]\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test = X[:int(len(data)*0.75)], X[int(len(data)*0.75):]\n",
    "y_train, y_test = y[:int(len(data)*0.75)], y[int(len(data)*0.75):]\n",
    "\n",
    "# Building the model\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,              # fraction of samples per tree\n",
    "    colsample_bytree=0.8,       # fraction of features per tree\n",
    "    num_class=25,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    objective='multi:softmax'\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
